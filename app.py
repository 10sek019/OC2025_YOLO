import streamlit as st
import cv2
import time
from ultralytics import YOLO
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase

# ãƒšãƒ¼ã‚¸æ§‹æˆã¨ãƒ¢ãƒ‡ãƒ«ã®å¯¾å¿œ
PAGES = {
    "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äººæ•°ã‚«ã‚¦ãƒ³ãƒˆ": "yolov8n.pt",
    "äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§æ¤œå‡º": "yolov8n.pt",
    "æ ¡ç« ã‚’æ¤œå‡ºã—ã¦ã¿ã‚ˆã†": "best.pt"
}

# ãƒšãƒ¼ã‚¸çŠ¶æ…‹ã®åˆæœŸåŒ–
if "page" not in st.session_state:
    st.session_state.page = "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äººæ•°ã‚«ã‚¦ãƒ³ãƒˆ"

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒšãƒ¼ã‚¸é¸æŠï¼ˆãƒœã‚¿ãƒ³ï¼‰
st.sidebar.title("ğŸ“‚ ãƒšãƒ¼ã‚¸é¸æŠ")
for name in PAGES.keys():
    if st.sidebar.button(name, key=name):
        st.session_state.page = name

# ç¾åœ¨ã®ãƒšãƒ¼ã‚¸
page = st.session_state.page
model_path = PAGES[page]

# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
st.title(f"ğŸ“· {page}")

#---

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äººæ•°ã‚«ã‚¦ãƒ³ãƒˆç”¨ã‚¯ãƒ©ã‚¹

class PersonCounter(VideoTransformerBase):
    def __init__(self):
        self.model = YOLO(PAGES["ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äººæ•°ã‚«ã‚¦ãƒ³ãƒˆ"])
        self.last_frame_time = time.time()
        self.target_fps = 5
        self.person_count = 0

    def transform(self, frame):
        current_time = time.time()
        if current_time - self.last_frame_time < 1 / self.target_fps:
            return frame.to_ndarray(format="bgr24")

        self.last_frame_time = current_time

        img = frame.to_ndarray(format="bgr24")
        flipped_img = cv2.flip(img, 1)

        results = self.model(flipped_img)
        
        count = 0
        for res in results:
            for box in res.boxes:
                class_id = int(box.cls)
                if self.model.names[class_id] != 'person':
                    continue

                x1, y1, x2, y2 = map(int, box.xyxy.tolist()[0])
                cv2.rectangle(flipped_img, (x1, y1), (x2, y2), (0, 255, 255), 5)
                count += 1
        
        # ã‚¯ãƒ©ã‚¹å†…ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã«ã‚«ã‚¦ãƒ³ãƒˆã‚’ä¿å­˜
        self.person_count = count
        
        return flipped_img

#---

### ä¸€èˆ¬ç‰©ä½“æ¤œå‡ºç”¨ã‚¯ãƒ©ã‚¹

class ObjectDetector(VideoTransformerBase):
    def __init__(self):
        self.model = YOLO(PAGES[page])
        self.last_frame_time = time.time()
        self.target_fps = 5
        
        if "æ ¡ç« ã‚’æ¤œå‡ºã—ã¦ã¿ã‚ˆã†" in page:
            self.conf = 0.6
        else:
            self.conf = 0.25

    def transform(self, frame):
        current_time = time.time()
        if current_time - self.last_frame_time < 1 / self.target_fps:
            return None
        self.last_frame_time = current_time
        
        img = frame.to_ndarray(format="bgr24")
        flipped_img = cv2.flip(img, 1)

        results = self.model(flipped_img, verbose=False, conf=self.conf)

        if "æ ¡ç« ã‚’æ¤œå‡ºã—ã¦ã¿ã‚ˆã†" in page:
            results[0].names = {0: "UOH"}

        annotated_img = results[0].plot()
        return annotated_img

#---

# å„ãƒšãƒ¼ã‚¸ã®å®Ÿè¡Œã¨UIã®æç”»
if page == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äººæ•°ã‚«ã‚¦ãƒ³ãƒˆ":
    ctx = webrtc_streamer(key="person-counter", video_processor_factory=PersonCounter)
    
    # æ˜ åƒå‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹é–“ã€äººæ•°è¡¨ç¤ºã‚’æ›´æ–°
    # ctx.video_processorãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ãã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚‰äººæ•°ã‚’å–å¾—
    if ctx.video_processor:
        # äººæ•°è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
        count_placeholder = st.empty()
        while True:
            # æœ€æ–°ã®äººæ•°ã‚’å–å¾—ã—ã¦è¡¨ç¤º
            if ctx.video_processor.person_count is not None:
                count_placeholder.markdown(f"## ğŸ‘¥ ç¾åœ¨ã®äººæ•°: **{ctx.video_processor.person_count}**")
            # é »ç¹ã«æ›´æ–°ã—ã™ããªã„ã‚ˆã†ã«å°‘ã—å¾…æ©Ÿ
            time.sleep(0.1)

else:
    webrtc_streamer(key="object-detector", video_processor_factory=ObjectDetector)